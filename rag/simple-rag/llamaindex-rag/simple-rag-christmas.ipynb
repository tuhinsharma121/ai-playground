{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "413825b6-e83d-4e23-88ac-0bb010ae269e",
   "metadata": {},
   "source": [
    "# Initialize Chromadb and create the indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ae6be9-9944-44b2-afa5-e866e3166158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18465e3f0400424980837aaefa817317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f4e4d84d0b414aaaaac2f96552b01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import Document\n",
    "\n",
    "# Load or create your document\n",
    "\n",
    "with open(\"./book.txt\") as f:\n",
    "    doc = f.read() \n",
    "text = doc\n",
    "\n",
    "\n",
    "document = Document(text=text)\n",
    "\n",
    "# Initialize Chroma client\n",
    "chroma_client = chromadb.EphemeralClient()\n",
    "\n",
    "# Create a collection for storing vectors\n",
    "chroma_collection = chroma_client.get_or_create_collection(\"book_collection\")\n",
    "\n",
    "# Create the vector store\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "# Initialize the storage context\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Create a sentence splitter for chunking text\n",
    "parser = SentenceSplitter(chunk_size=1024, chunk_overlap=20)\n",
    "\n",
    "# Build the index\n",
    "index = VectorStoreIndex.from_documents([document], storage_context=storage_context, \n",
    "                                        transformations=[parser], show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eeafc7-e1c7-488a-bfa5-364412d3318b",
   "metadata": {},
   "source": [
    "# Initialize RAG and run a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b21100d-4436-4dd7-a79d-065771a11f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dickens uses settings like a bleak moor and a desolate lighthouse to reflect Scrooge's cold and isolated personality.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "retriever = VectorIndexRetriever(index, similarity_top_k=3, filter=None)\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever, llm=llm)\n",
    "\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "new_prompt_template_str = (\n",
    "    \"Context information is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context and not prior knowledge, \"\n",
    "    \"answer the query in less than 15 words.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "\n",
    "new_prompt_template = PromptTemplate(new_prompt_template_str)\n",
    "query_engine.update_prompts({\"response_synthesizer:text_qa_template\": new_prompt_template})\n",
    "\n",
    "query = \"\"\"\"How does Dickens establish Scrooge's character through \n",
    "environmental imagery rather than direct description? \n",
    "Make sure the answer does not exceed 300 characters.\"\"\"\n",
    "\n",
    "response = query_engine.query(query)\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a2228-7ab4-444f-a66c-0d4d25aedd42",
   "metadata": {},
   "source": [
    "# Load the golden QnA data generated by Claude 3.7 Sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd018b2-4f06-478e-b464-75be5f55f5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_question</th>\n",
       "      <th>reference_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What literary device does Dickens use in the o...</td>\n",
       "      <td>Repetition (\"Marley was dead\") and paradox (\"d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the symbolic significance of Scrooge k...</td>\n",
       "      <td>It symbolizes Scrooge's inability to let go of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does Dickens establish Scrooge's character...</td>\n",
       "      <td>Through cold imagery: he \"iced his office,\" ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the thematic purpose of the contrast b...</td>\n",
       "      <td>It juxtaposes institutional cruelty with famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What narrative technique does Dickens use when...</td>\n",
       "      <td>Contradictory descriptors (\"like a child; yet ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  reference_question  \\\n",
       "0  What literary device does Dickens use in the o...   \n",
       "1  What is the symbolic significance of Scrooge k...   \n",
       "2  How does Dickens establish Scrooge's character...   \n",
       "3  What is the thematic purpose of the contrast b...   \n",
       "4  What narrative technique does Dickens use when...   \n",
       "\n",
       "                                    reference_answer  \n",
       "0  Repetition (\"Marley was dead\") and paradox (\"d...  \n",
       "1  It symbolizes Scrooge's inability to let go of...  \n",
       "2  Through cold imagery: he \"iced his office,\" ca...  \n",
       "3  It juxtaposes institutional cruelty with famil...  \n",
       "4  Contradictory descriptors (\"like a child; yet ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"golden_data.json\")\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98ffdfd-d6da-4916-9fa1-0a3e164a5003",
   "metadata": {},
   "source": [
    "# Lets call RAG to get the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "227adc74-e5b3-490e-bfe8-5a1063cd6d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [01:59<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "reference_questions = df[\"reference_question\"].tolist()\n",
    "reference_answers = df[\"reference_answer\"].tolist()\n",
    "rag_answers = list()\n",
    "\n",
    "for i in tqdm.tqdm(range(len(reference_questions))):\n",
    "    rag_answer = query_engine.query(reference_questions[i])\n",
    "    rag_answers.append(rag_answer.response)\n",
    "\n",
    "df[\"simple_rag_answer\"] = rag_answers\n",
    "df.to_json(\"result_simple_rag.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f6447-9309-4345-b30a-6b54a53c4f5e",
   "metadata": {},
   "source": [
    "# Define the evaluation code using GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c3cb407-c4af-49f4-adc4-9ea09bc8a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# First, set the API key\n",
    "openai_client = openai.OpenAI()  # <-- create a client\n",
    "\n",
    "def evaluate_with_llm(question, golden, prediction):\n",
    "    prompt = f\"\"\"\n",
    "    Question: {question}\n",
    "    Golden Answer: {golden}\n",
    "    Model Answer: {prediction}\n",
    "\n",
    "    Evaluate the model answer against the golden answer. \n",
    "    Respond with a score between 1 (poor) and 5 (perfect) based on accuracy, relevance, and completeness.\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4\",  # or \"gpt-3.5-turbo\"\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert evaluator.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    result_text = response.choices[0].message.content\n",
    "    return result_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323b28a6-b492-44a4-91b6-6ca6a69cb71f",
   "metadata": {},
   "source": [
    "# Call the Evaluation method for all the golden examples and store the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db909042-ec10-41ac-aabe-203a76e0816f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98it [01:14,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_json(\"result_simple_rag.json\")\n",
    "reference_questions = df[\"reference_question\"].tolist()\n",
    "reference_answers = df[\"reference_answer\"].tolist()\n",
    "rag_answers = df[\"simple_rag_answer\"].tolist()\n",
    "eval_scores = list()\n",
    "\n",
    "for reference_question,reference_answer,rag_answer in tqdm(zip(reference_questions,reference_answers,rag_answers)):\n",
    "    eval_scores.append(evaluate_with_llm(reference_question,reference_answer,rag_answer))\n",
    "\n",
    "df[\"gpt4_score\"] = eval_scores\n",
    "df.to_json(\"result_simple_rag_score.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412e1a4-3a11-49e1-96cd-66eaac4e6a8b",
   "metadata": {},
   "source": [
    "# Mean score for all the examples in the golden dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f685bb7f-b72b-47ee-a6f1-7a9dbc4f3f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.683928571428572)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"result_simple_rag_score.json\")\n",
    "df[\"gpt4_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcfca67-22ab-4a60-8020-f29a4c282723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
