{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5375bad0-caf7-43b8-9541-09ddde32a746",
   "metadata": {},
   "source": [
    "# Read the data from book.txt, chunk and create docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fface0f3-8199-4253-bdf3-8f2318b11aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "nest_asyncio.apply()\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import Document\n",
    "\n",
    "# Load or create your document\n",
    "with open(\"./book.txt\") as f:\n",
    "    doc = f.read() \n",
    "document = Document(text=doc)\n",
    "\n",
    "# Initialize the splitter\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=1024,    # Maximum number of characters per chunk\n",
    "    chunk_overlap=20,   # Number of characters overlapping between chunks\n",
    ")\n",
    "\n",
    "# Parse the document into sentence-level nodes\n",
    "nodes = splitter.get_nodes_from_documents([document])\n",
    "\n",
    "docs = list()\n",
    "# Each node contains a sentence\n",
    "for node in nodes:\n",
    "    docs.append(node.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413825b6-e83d-4e23-88ac-0bb010ae269e",
   "metadata": {},
   "source": [
    "# Initialize Fast GraphRAG and create the indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38114468-441c-41dc-a906-9beecef3afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import instructor\n",
    "from dotenv import load_dotenv\n",
    "from fast_graphrag import GraphRAG\n",
    "from fast_graphrag._llm import OpenAIEmbeddingService, OpenAILLMService\n",
    "\n",
    "\n",
    "DOMAIN = \"Analyze this story and identify the characters. \\\n",
    "Focus on how they interact with each other, \\\n",
    "the locations they explore, and their relationships.\"\n",
    "\n",
    "QUERIES = [\n",
    "    \"What is the significance of Christmas Eve in A Christmas Carol?\",\n",
    "    \"How does the setting of Victorian London contribute to the story's themes?\",\n",
    "    \"Describe the chain of events that leads to Scrooge's transformation.\",\n",
    "    \"How does Dickens use the different spirits (Past, Present, and Future) to guide Scrooge?\",\n",
    "    \"Why does Dickens choose to divide the story into \\\"staves\\\" rather than chapters?\"\n",
    "]\n",
    "\n",
    "ENTITY_TYPES = [\"Character\", \"Animal\", \"Place\", \"Object\", \"Activity\", \"Event\"]\n",
    "save_dir = 'fastgraphrag_books'\n",
    "llm_model_name = 'gpt-3.5-turbo'\n",
    "embedding_model_name = 'text-embedding-3-small'\n",
    "\n",
    "fast_grag = GraphRAG(\n",
    "    working_dir=save_dir,\n",
    "    domain=DOMAIN,\n",
    "    example_queries=\"\\n\".join(QUERIES),\n",
    "    entity_types=ENTITY_TYPES,\n",
    "    config=GraphRAG.Config(\n",
    "        llm_service=OpenAILLMService(\n",
    "            model=llm_model_name,\n",
    "        ),\n",
    "        embedding_service=OpenAIEmbeddingService(\n",
    "            model=embedding_model_name,\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "for doc in docs:\n",
    "    fast_grag.insert(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110b44a-82f7-44d9-a964-d649ab756de0",
   "metadata": {},
   "source": [
    "# Test a sample query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97885389-d7ae-4d7a-9f68-7cc21bfc07ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dickens establishes Scrooge's character through the environmental imagery of a lonely, dark house, with no soul expressing kindness towards him, contrasting his unfeeling nature with a warm, bustling family scene filled with laughter and joy.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\"How does Dickens establish Scrooge's character through \n",
    "environmental imagery rather than direct description? \n",
    "Make sure the answer does not exceed 300 characters.\"\"\"\n",
    "\n",
    "print(fast_grag.query(query).response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a2228-7ab4-444f-a66c-0d4d25aedd42",
   "metadata": {},
   "source": [
    "# Load the golden QnA data generated by Claude 3.7 Sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd018b2-4f06-478e-b464-75be5f55f5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_question</th>\n",
       "      <th>reference_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What literary device does Dickens use in the o...</td>\n",
       "      <td>Repetition (\"Marley was dead\") and paradox (\"d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the symbolic significance of Scrooge k...</td>\n",
       "      <td>It symbolizes Scrooge's inability to let go of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does Dickens establish Scrooge's character...</td>\n",
       "      <td>Through cold imagery: he \"iced his office,\" ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the thematic purpose of the contrast b...</td>\n",
       "      <td>It juxtaposes institutional cruelty with famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What narrative technique does Dickens use when...</td>\n",
       "      <td>Contradictory descriptors (\"like a child; yet ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  reference_question  \\\n",
       "0  What literary device does Dickens use in the o...   \n",
       "1  What is the symbolic significance of Scrooge k...   \n",
       "2  How does Dickens establish Scrooge's character...   \n",
       "3  What is the thematic purpose of the contrast b...   \n",
       "4  What narrative technique does Dickens use when...   \n",
       "\n",
       "                                    reference_answer  \n",
       "0  Repetition (\"Marley was dead\") and paradox (\"d...  \n",
       "1  It symbolizes Scrooge's inability to let go of...  \n",
       "2  Through cold imagery: he \"iced his office,\" ca...  \n",
       "3  It juxtaposes institutional cruelty with famil...  \n",
       "4  Contradictory descriptors (\"like a child; yet ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"golden_data.json\")\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98ffdfd-d6da-4916-9fa1-0a3e164a5003",
   "metadata": {},
   "source": [
    "# Lets call graphrag to get the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "227adc74-e5b3-490e-bfe8-5a1063cd6d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [05:21<00:00,  3.28s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "reference_questions = df[\"reference_question\"].tolist()\n",
    "reference_answers = df[\"reference_answer\"].tolist()\n",
    "graphrag_answers = list()\n",
    "\n",
    "for i in tqdm.tqdm(range(len(reference_questions))):\n",
    "    graphrag_answer = fast_grag.query(reference_questions[i]).response\n",
    "    graphrag_answers.append(graphrag_answer)\n",
    "\n",
    "df[\"fastgraphrag_answer\"] = graphrag_answers\n",
    "df.to_json(\"result_fastgraphrag.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f6447-9309-4345-b30a-6b54a53c4f5e",
   "metadata": {},
   "source": [
    "# Define the evaluation code using GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c3cb407-c4af-49f4-adc4-9ea09bc8a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai_client = openai.OpenAI()\n",
    "\n",
    "def evaluate_with_llm(question, golden, prediction):\n",
    "    prompt = f\"\"\"\n",
    "    Question: {question}\n",
    "    Golden Answer: {golden}\n",
    "    Model Answer: {prediction}\n",
    "\n",
    "    Evaluate the model answer against the golden answer. \n",
    "    Respond with a score between 1 (poor) and 5 (perfect) based on accuracy, relevance, and completeness.\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert evaluator.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    result_text = response.choices[0].message.content\n",
    "    return result_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323b28a6-b492-44a4-91b6-6ca6a69cb71f",
   "metadata": {},
   "source": [
    "# Call the Evaluation method for all the golden examples and store the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db909042-ec10-41ac-aabe-203a76e0816f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98it [01:13,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_json(\"result_fastgraphrag.json\")\n",
    "reference_questions = df[\"reference_question\"].tolist()\n",
    "reference_answers = df[\"reference_answer\"].tolist()\n",
    "graphrag_answers = df[\"fastgraphrag_answer\"].tolist()\n",
    "eval_scores = list()\n",
    "\n",
    "for reference_question,reference_answer,graphrag_answer in tqdm(zip(reference_questions,reference_answers,graphrag_answers)):\n",
    "    eval_scores.append(evaluate_with_llm(reference_question,reference_answer,graphrag_answer))\n",
    "\n",
    "df[\"gpt4_score\"] = eval_scores\n",
    "df.to_json(\"result_fastgraphrag_score.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412e1a4-3a11-49e1-96cd-66eaac4e6a8b",
   "metadata": {},
   "source": [
    "# Mean score for all the examples in the golden dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f685bb7f-b72b-47ee-a6f1-7a9dbc4f3f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.028061224489796"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"result_fastgraphrag_score.json\")\n",
    "df[\"gpt4_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb0fe4c-60dd-4b28-8a79-8fce3342936a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c46cc84-83bf-4788-9c2d-991d6752aad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
